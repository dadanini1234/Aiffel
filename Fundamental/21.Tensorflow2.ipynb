{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4900393",
   "metadata": {},
   "source": [
    "# 21. TF2 API 개요\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e3cd16",
   "metadata": {},
   "source": [
    "- Tensorflow V2의 개요와 특징을 파악한다.\n",
    "- Tensorflow V2의 3가지 주요 API 구성 방식을 이해하고 활용할 수 있다.\n",
    "- GradientTape를 활용해 보고 좀 더 로우 레벨의 딥러닝 구현 방식을 이해한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d15532",
   "metadata": {},
   "source": [
    "## 21-2. TensorFlow2 API로 모델 구성하기\n",
    "\n",
    "간단한 이미지 분류문제를 풀어 tensorflow2를 활용한 모델링을 해보자\n",
    "\n",
    "방법은 크게 세가지가 있음\n",
    "- Sequential\n",
    "- Functional\n",
    "- Model Subclassing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b526f3a",
   "metadata": {},
   "source": [
    "### 1) TensorFlow2 Sequential Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62308949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(__넣고싶은 레이어__)\n",
    "model.add(__넣고싶은 레이어__)\n",
    "model.add(__넣고싶은 레이어__)\n",
    "\n",
    "model.fit(x, y, epochs=10, batch_size=32)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b5a54",
   "metadata": {},
   "source": [
    "=> 앞서 공부한 모델의 형식\n",
    "\n",
    "입력부터 출력까지 레이어를 그야말로 Sequential하게 차곡차곡 add해서 쌓아나가기만 하면 된다.\n",
    "\n",
    "- 장점 : 초보자가 하기에 매우 쉽다\n",
    "- 단점 : 모델의 입력과 출력이 여러 개인 경우에는 적합하지 않음(입력 1, 출력1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8255996",
   "metadata": {},
   "source": [
    "### 2) TensorFlow2 Functional API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2939de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "inputs = keras.Input(shape=(__원하는 입력값 모양__))\n",
    "x = keras.layers.__넣고싶은 레이어__(관련 파라미터)(input)\n",
    "x = keras.layers.__넣고싶은 레이어__(관련 파라미터)(x)\n",
    "outputs = keras.layers.__넣고싶은 레이어__(관련 파라미터)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.fit(x,y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ade20c2",
   "metadata": {},
   "source": [
    "여기서 다른점은 keras.Model을 쓰는 것이다. -> Sequential Model을 쓰는 것보다 더 일반적인 접근임 왜냐면 시퀀셜은 케라스를 상속받아서 확장한 사례이기 때문이다\n",
    "\n",
    "- 입력과 출력을 규정함으써 모델 전체를 규정한다.\n",
    "- input이 되는 텐서가 여러 개가 될 수 있다.\n",
    "- 그 레이어들을 엮어 output까지 규정한다.\n",
    "- Functional API를 통해 다중 입력/출력을 가지는 모델을 구성할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8695ecfe",
   "metadata": {},
   "source": [
    "### 3) TensorFlow2 Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.__정의하고자 하는 레이어__()\n",
    "        self.__정의하고자 하는 레이어__()\n",
    "        self.__정의하고자 하는 레이어__()\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.__정의하고자 하는 레이어__(x)\n",
    "        x = self.__정의하고자 하는 레이어__(x)\n",
    "        x = self.__정의하고자 하는 레이어__(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = CustomModel()\n",
    "model.fit(x,y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1384a69",
   "metadata": {},
   "source": [
    "- 제일 자유로운 모델링을 진행할 수 있다.\n",
    "- 본질적으로는 Functional한 접근이랑 차이가 없음\n",
    "- keras를 상속받은 모델 클래스를 만드는 것이라서\n",
    "- init() 메서드 안에서 레이어 구성\n",
    "- call() 메서드 안에서 레이어 간 forward propagation을 구현\n",
    "- 레이어에 대한 깊은 이해가 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df635f61",
   "metadata": {},
   "source": [
    "## 21-3. Tensorflow2 API로 모델 작성하기: MNIST (1) Sequential API 활용\n",
    "\n",
    "Tensorflow2의 다양한 Highlevel API를 활용해서 이미지 문제를 풀어보자\n",
    "\n",
    "- MNIST 문제 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9880f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af591c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a11c333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model을 구성해주세요.\n",
    "\"\"\"\n",
    "Spec:\n",
    "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "3. Flatten 레이어\n",
    "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4114eea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 9s 3ms/step - loss: 0.1054 - accuracy: 0.9672\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0346 - accuracy: 0.9891\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0200 - accuracy: 0.9937\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0134 - accuracy: 0.9958\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0097 - accuracy: 0.9966\n",
      "313/313 - 1s - loss: 0.0393 - accuracy: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.039258308708667755, 0.9905999898910522]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed53a1e",
   "metadata": {},
   "source": [
    "## 21-4. Tensorflow2 API로 모델 작성하기: MNIST (2) Functional API 활용\n",
    "\n",
    "keras.Input으로 정의된 input 및 output 레이어 구성을 통해 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc7aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0248fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dfdbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Spec:\n",
    "0. (28X28X1) 차원으로 정의된 Input\n",
    "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "3. Flatten 레이어\n",
    "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "\n",
    "# 여기에 모델을 구성해 주세요.\n",
    "\n",
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = keras.layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(128, activation='relu')(x)\n",
    "outputs = keras.layers.Dense(10, activation='relu')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb030098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 2.3389 - accuracy: 0.1062\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3024 - accuracy: 0.0988\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3024 - accuracy: 0.0988\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3024 - accuracy: 0.0988\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3023 - accuracy: 0.0989\n",
      "313/313 - 1s - loss: 2.3026 - accuracy: 0.0980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.30259108543396, 0.09799999743700027]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b42338",
   "metadata": {},
   "source": [
    "## 21-5. Tensorflow2 API로 모델 작성하기: MNIST (3) Subclassing 활용\n",
    "\n",
    "- init 메서드 안에서 레이어 선언, call 메서드 안에서 forward propagation 구현\n",
    "- call 의 입력이 input, 리턴값이 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0e2fe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2f51e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclassing을 활용한 Model을 구성해주세요.\n",
    "\"\"\"\n",
    "Spec:\n",
    "0. keras.Model 을 상속받았으며, __init__()와 call() 메서드를 가진 모델 클래스\n",
    "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "3. Flatten 레이어\n",
    "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "6. call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n",
    "\"\"\"\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.conv2 = keras.layers.Conv2D(64, 3, activation='relu')\n",
    "        self.flat = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(128, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(10, activation='softmax')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2ebf6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 2.3026 - accuracy: 0.0987\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0987\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0987\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0987\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0987\n",
      "313/313 - 1s - loss: 2.3026 - accuracy: 0.0980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.30259108543396, 0.09799999743700027]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df05a771",
   "metadata": {},
   "source": [
    "## 21-6. TensorFlow2 API로 모델 작성 및 학습하기: CIFAR-100 (1) Sequential API 활용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c89fc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf426f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model을 구성해주세요.\n",
    "\"\"\"\n",
    "Spec:\n",
    "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. pool_size가 2인 MaxPool 레이어\n",
    "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "4. pool_size가 2인 MaxPool 레이어\n",
    "5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "\n",
    "# 여기에 모델을 구성해주세요\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dbdf7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.6352 - accuracy: 0.1544\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9051 - accuracy: 0.2835\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5981 - accuracy: 0.3476\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3891 - accuracy: 0.3898\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2182 - accuracy: 0.4252\n",
      "313/313 - 1s - loss: 2.5675 - accuracy: 0.3602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5674729347229004, 0.3601999878883362]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "# 학습 관련 부분을 작성해주세요\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d77de",
   "metadata": {},
   "source": [
    "## 21-7. Tensorflow2 API로 모델 작성 및 학습하기: CIFAR-100 (2) Functional API 활용\n",
    "\n",
    "keras.Input으로 정의된 input 및 output 레이어 구성을 통해 model 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e109d8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bf777d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API를 활용한 Model을 구성해주세요.\n",
    "\"\"\"\n",
    "Spec:\n",
    "0. (32X32X3) 차원으로 정의된 Input\n",
    "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. pool_size가 2인 MaxPool 레이어\n",
    "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "4. pool_size가 2인 MaxPool 레이어\n",
    "5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "\n",
    "# 여기에 모델을 구성해주세요\n",
    "\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = keras.layers.Conv2D(16, 3, activation='relu')(inputs)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a7ded1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.5950 - accuracy: 0.1607\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.8906 - accuracy: 0.2854\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5763 - accuracy: 0.3481\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3680 - accuracy: 0.3915\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2044 - accuracy: 0.4294\n",
      "313/313 - 1s - loss: 2.5434 - accuracy: 0.3601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.543390989303589, 0.36010000109672546]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "# 학습 관련 부분을 작성해주세요\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fb1a65",
   "metadata": {},
   "source": [
    "## 21-8. Tensorflow2 API로 모델 작성 및 학습하기: CIFAR-100 (3) Subclassing 활용\n",
    "\n",
    "- init 메서드 안에서 레이어 선언, call 메서드 안에서 forward propagation 구현\n",
    "- call 의 입력이 input, 리턴값이 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61c10f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclassing을 활용한 Model을 구성해주세요.\n",
    "\"\"\"\n",
    "Spec:\n",
    "0. keras.Model 을 상속받았으며, __init__()와 call() 메서드를 가진 모델 클래스\n",
    "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. pool_size가 2인 MaxPool 레이어\n",
    "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "4. pool_size가 2인 MaxPool 레이어\n",
    "5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "7. call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n",
    "\"\"\"\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flat = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29b13c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.7301 - accuracy: 0.1347\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.0330 - accuracy: 0.2560\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.7563 - accuracy: 0.3106\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5773 - accuracy: 0.3465\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4459 - accuracy: 0.3744\n",
      "313/313 - 1s - loss: 2.6158 - accuracy: 0.3494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.615846872329712, 0.34940001368522644]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "# 학습 관련 부분을 작성해주세요\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f6d0e",
   "metadata": {},
   "source": [
    "## 21-9. GradientTape의 활용\n",
    "\n",
    "### Automatic differentiation - GradientTape\n",
    "\n",
    "- Tensorflow에서 제공하는 tf.GradientTape는 진행된 모든 연산의 중간 레이어값을 tape에 기록하고, 이를 이용해 gradient를 계산한 후 tape를 폐기하는 기능을 수행한다.\n",
    "- 이전 스텝에서 진행했던 학습을 tf.GradientTape를 이용한 것으로 변형해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e8865ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "# 모델 구성부분\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922afee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "-> 이부분을 바꿔보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c004d4",
   "metadata": {},
   "source": [
    "저렇게 loss, optimizer를 지정해주면 내부적으로는 매 스텝 학습이 진행될 때마다 발생하는 로스와 그래디언트가 model.compile()안에서 자동으로 진행된다.\n",
    "\n",
    "이제 밑에 코드는 tape.gradient()를 통해 매 스텝 발생하는 그래디언트를 추출한 후 optimizer.apply_gradients()를 통해 발생한 그래디언트가 업데이트 할 파라미터 model.trainable_variavles를 지정해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ce90cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# tf.GradientTape()를 활용한 train_step\n",
    "def train_step(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features)\n",
    "        loss = loss_func(labels, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35c7734",
   "metadata": {},
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
    "-> 이것도 바꿔보자\n",
    "\n",
    "배치학습 과정을 위에 train_step()을 호출하도록 바꿔서 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16e40867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: last batch loss = 3.0877\n",
      "Epoch 1: last batch loss = 2.5430\n",
      "Epoch 2: last batch loss = 2.2160\n",
      "Epoch 3: last batch loss = 2.0193\n",
      "Epoch 4: last batch loss = 1.8471\n",
      "It took 72.20368504524231 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def train_model(batch_size=32):\n",
    "    start = time.time()\n",
    "    for epoch in range(5):\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for step, (x, y) in enumerate(zip(x_train, y_train)):\n",
    "            x_batch.append(x)\n",
    "            y_batch.append(y)\n",
    "            if step % batch_size == batch_size-1:\n",
    "                loss = train_step(np.array(x_batch, dtype=np.float32), np.array(y_batch, dtype=np.float32))\n",
    "                x_batch = []\n",
    "                y_batch = []\n",
    "        print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
    "    print(\"It took {} seconds\".format(time.time() - start))\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5a128a",
   "metadata": {},
   "source": [
    "train_model() = model.fit()과 같음\n",
    "\n",
    "tf.GradientTape()을 활용해 compile과 fit의 메서드를 꺼내 재구성이 가능하다\n",
    "\n",
    "강화학습 또는 GAN의 학습을 위해 train_step 메서드의 재구성이 중요하니까 숙지해두자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "394f3659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 702ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3492"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "prediction = model.predict(x_test, batch_size=x_test.shape[0], verbose=1)\n",
    "temp = sum(np.squeeze(y_test) == np.argmax(prediction, axis=1))\n",
    "temp/len(y_test)  # Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8449f772",
   "metadata": {},
   "source": [
    "충분히 학습을 진행한 상태가 아니므로 최종 accuracy 값은 무시해도 괜찮다! 끝!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
